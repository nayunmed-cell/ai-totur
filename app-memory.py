import streamlit as st
import google.generativeai as genai

# 1. é¡µé¢é…ç½®
st.title("ğŸ§  çœŸæ­£æœ‰è®°å¿†çš„ AI åŠ©æ‰‹")

# 2. é…ç½® API Key (è®°å¾—æ›¿æ¢!)
genai.configure(api_key="AIzaSyCIKfyIAA304m78JQyZMKE3GEHOW3Ce6MM")
model = genai.GenerativeModel('gemini-2.5-flash')

# 3. åˆå§‹åŒ–èŠå¤©å†å² (è¿™æ˜¯ä¸€ä¸ªç®€å•çš„åˆ—è¡¨ï¼Œä¸“é—¨ç”¨æ¥å­˜æ–‡æœ¬)
# åªè¦ç½‘é¡µä¸å…³ï¼Œè¿™ä¸ªåˆ—è¡¨å°±åœ¨
if "messages" not in st.session_state:
    st.session_state.messages = []

# 4. åœ¨ç½‘é¡µä¸Šç”»å‡ºå†å²è®°å½•
# æ¯æ¬¡åˆ·æ–°ï¼Œå…ˆæŠŠå®ƒç”»å‡ºæ¥
for msg in st.session_state.messages:
    # è¿™é‡Œçš„ msg["role"] æ˜¯ 'user' æˆ– 'assistant'
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 5. å¤„ç†æ–°çš„è¾“å…¥
if prompt := st.chat_input("Hi..."):
    # A. å…ˆæŠŠç”¨æˆ·çš„è¿™å¥è¯ç”»å‡ºæ¥ï¼Œå¹¶å­˜è¿›æˆ‘ä»¬çš„åˆ—è¡¨
    with st.chat_message("user"):
        st.write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # B. å…³é”®æ­¥éª¤ï¼šæ„å»º AI èƒ½çœ‹æ‡‚çš„â€œå†å²æ¡£æ¡ˆâ€
    # æˆ‘ä»¬è¦æŠŠ Streamlit çš„æ ¼å¼ (user/assistant) è½¬æ¢æˆ Gemini çš„æ ¼å¼ (user/model)
    gemini_history = []
    for msg in st.session_state.messages:
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({"role": role, "parts": [msg["content"]]})
    
    # C. è°ƒç”¨ AI
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            # è¿™é‡Œçš„é­”æ³•æ˜¯ï¼šæˆ‘ä»¬ä¸ç›´æ¥å‘ä¸€å¥è¯
            # è€Œæ˜¯å¼€å¯ä¸€ä¸ªæ–°èŠå¤©ï¼ŒæŠŠåˆšæ‰æ•´ç†å¥½çš„ã€å…¨éƒ¨å†å²ã€‘ç¬é—´å¡ç»™å®ƒ
            # è¿™æ ·å®ƒå°±â€œæƒ³èµ·â€äº†ä¸€åˆ‡
            chat = model.start_chat(history=gemini_history)
            
            # å› ä¸º history é‡Œå·²ç»åŒ…å«äº†ä½ åˆšæ‰è¯´çš„è¯ï¼Œ
            # æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å…¶å®ä¸éœ€è¦å† send_message(prompt)ï¼Œ
            # ä½†å› ä¸º start_chat çš„ history ä¸åŒ…å«â€œå½“å‰è¿™ä¸€è½®çš„è§¦å‘â€ï¼Œ
            # æˆ‘ä»¬åˆšæ‰åªæ˜¯æŠŠ prompt å­˜è¿›äº† history åˆ—è¡¨é‡Œç”¨æ¥æ„å»ºä¸Šä¸‹æ–‡ã€‚
            # ç¨ç­‰ï¼Œä¸ºäº†é€»è¾‘æœ€ç®€å•ï¼Œæˆ‘ä»¬æŠŠ prompt ä» gemini_history é‡Œæ‹¿å‡ºæ¥å‘ã€‚
            
            # ä¿®æ­£é€»è¾‘ï¼š
            # 1. å†å²è®°å½• = é™¤äº†åˆšæ‰é‚£å¥ prompt ä¹‹å¤–çš„æ‰€æœ‰è®°å½•
            history_input = gemini_history[:-1] 
            # 2. å¯åŠ¨å¸¦æœ‰æ—§è®°å¿†çš„èŠå¤©
            chat = model.start_chat(history=history_input)
            # 3. å‘é€æœ€æ–°çš„ä¸€å¥è¯
            response = chat.send_message(prompt)
            
            st.write(response.text)
    
    # D. æŠŠ AI çš„å›å¤ä¹Ÿå­˜è¿›æˆ‘ä»¬çš„åˆ—è¡¨
    st.session_state.messages.append({"role": "assistant", "content": response.text})